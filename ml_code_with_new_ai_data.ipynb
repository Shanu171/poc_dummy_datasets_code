{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66832890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Updated to your uploaded files in /mnt/data\n",
    "CLAIM_FILE_PATH = '/mnt/data/uk_pmi_claims_200k.csv'\n",
    "MEMBER_FILE_PATH = '/mnt/data/uk_pmi_membership_120k.csv'\n",
    "\n",
    "# Claim Columns\n",
    "CLAIM_AMOUNT_COL = 'Claim Amount'\n",
    "CLAIM_DATE_COL = 'Incurred Date'\n",
    "CLAIM_MEMBER_ID_COL = 'Unique Member Reference'\n",
    "CLAIM_TYPE_COL = 'Claim Type'\n",
    "CLAIM_LOS_COL = 'Calculated Length of Service'\n",
    "CONDITION_CATEGORY_COL = 'Condition Category'\n",
    "\n",
    "# Member Columns\n",
    "MEMBER_ID_COL = 'Unique Member Reference'\n",
    "MEMBER_DOB_COL = 'Year of Birth'\n",
    "MEMBER_JOIN_DATE_COL = 'Original Date of Joining'\n",
    "MEMBER_GENDER_COL = 'Gender'\n",
    "MEMBER_POSTCODE_COL = 'Short Post Code of Member'\n",
    "MEMBER_SCHEME_COL = 'Scheme Category/ Section Name'\n",
    "MEMBER_STATUS_COL = 'Status of Member'\n",
    "\n",
    "START_YEAR = 2019\n",
    "END_YEAR = 2025\n",
    "VALIDATION_YEAR = 2025\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 2. LOAD AND CLEAN DATA\n",
    "# ==============================================================================\n",
    "def load_data(claim_path, member_path):\n",
    "    try:\n",
    "        try:\n",
    "            df_claims = pd.read_csv(claim_path)\n",
    "            df_members = pd.read_csv(member_path)\n",
    "        except UnicodeDecodeError:\n",
    "            df_claims = pd.read_csv(claim_path, encoding='latin1')\n",
    "            df_members = pd.read_csv(member_path, encoding='latin1')\n",
    "\n",
    "        print(f\"Successfully loaded {claim_path} and {member_path}\")\n",
    "\n",
    "        claim_cols_to_keep = [\n",
    "            CLAIM_MEMBER_ID_COL, CLAIM_DATE_COL, CLAIM_AMOUNT_COL,\n",
    "            CLAIM_TYPE_COL, CLAIM_LOS_COL, CONDITION_CATEGORY_COL\n",
    "        ]\n",
    "        df_claims = df_claims[claim_cols_to_keep].copy()\n",
    "\n",
    "        df_claims[CLAIM_DATE_COL] = pd.to_datetime(df_claims[CLAIM_DATE_COL], errors='coerce')\n",
    "        df_claims['claim_year'] = df_claims[CLAIM_DATE_COL].dt.year\n",
    "        df_claims[CLAIM_AMOUNT_COL] = pd.to_numeric(df_claims[CLAIM_AMOUNT_COL], errors='coerce')\n",
    "        df_claims[CLAIM_LOS_COL] = pd.to_numeric(df_claims[CLAIM_LOS_COL], errors='coerce')\n",
    "        df_claims = df_claims.dropna(subset=[CLAIM_DATE_COL, CLAIM_MEMBER_ID_COL, CLAIM_AMOUNT_COL])\n",
    "        df_claims = df_claims[df_claims['claim_year'].between(START_YEAR, END_YEAR)]\n",
    "\n",
    "        member_cols_to_keep = [\n",
    "            MEMBER_ID_COL, MEMBER_DOB_COL, MEMBER_JOIN_DATE_COL,\n",
    "            MEMBER_GENDER_COL, MEMBER_POSTCODE_COL, MEMBER_SCHEME_COL, MEMBER_STATUS_COL\n",
    "        ]\n",
    "        df_members = df_members[member_cols_to_keep].copy()\n",
    "        df_members[MEMBER_JOIN_DATE_COL] = pd.to_datetime(df_members[MEMBER_JOIN_DATE_COL], errors='coerce')\n",
    "        df_members[MEMBER_ID_COL] = df_members[MEMBER_ID_COL].astype(str)\n",
    "        df_claims[CLAIM_MEMBER_ID_COL] = df_claims[CLAIM_MEMBER_ID_COL].astype(str)\n",
    "        df_members = df_members.drop_duplicates(subset=[MEMBER_ID_COL])\n",
    "\n",
    "        print(f\"Data cleaning complete. Claims: {len(df_claims)}, Members: {len(df_members)}\")\n",
    "        return df_claims, df_members\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: One of the files was not found.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data loading: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 3. CREATE MEMBER-YEAR SCAFFOLD\n",
    "# ==============================================================================\n",
    "def create_scaffold(df_claims, df_members, start_year, end_year):\n",
    "    print(\"Creating member-year scaffold...\")\n",
    "\n",
    "    def had_condition(series, keyword):\n",
    "        return (series.str.contains(keyword, case=False, na=False)).any()\n",
    "\n",
    "    aggregation_rules = {\n",
    "        'total_claim_amount': (CLAIM_AMOUNT_COL, 'sum'),\n",
    "        'total_claim_count': (CLAIM_AMOUNT_COL, 'count'),\n",
    "        'total_los': (CLAIM_LOS_COL, 'sum'),\n",
    "        'count_inpatient': (CLAIM_TYPE_COL, lambda x: (x == 'Inpatient').any()),\n",
    "        'unique_conditions_count': (CONDITION_CATEGORY_COL, 'nunique'),\n",
    "        'had_cardio': (CONDITION_CATEGORY_COL, lambda s: had_condition(s, 'Cardio')),\n",
    "        'had_musculo': (CONDITION_CATEGORY_COL, lambda s: had_condition(s, 'Musculo')),\n",
    "        'had_gastro': (CONDITION_CATEGORY_COL, lambda s: had_condition(s, 'Gastro')),\n",
    "        'had_chemo': (CONDITION_CATEGORY_COL, lambda s: had_condition(s, 'Chemo')),\n",
    "    }\n",
    "\n",
    "    # perform aggregation\n",
    "    df_agg = df_claims.groupby([CLAIM_MEMBER_ID_COL, 'claim_year']).agg(**aggregation_rules).reset_index()\n",
    "    df_agg = df_agg.rename(columns={'claim_year': 'year', CLAIM_MEMBER_ID_COL: MEMBER_ID_COL})\n",
    "\n",
    "    # scaffold\n",
    "    all_members = df_members[MEMBER_ID_COL].unique()\n",
    "    all_years = list(range(start_year, end_year + 1))\n",
    "    scaffold_index = pd.MultiIndex.from_product([all_members, all_years], names=[MEMBER_ID_COL, 'year'])\n",
    "    df_scaffold = pd.DataFrame(index=scaffold_index).reset_index()\n",
    "\n",
    "    df_master = pd.merge(df_scaffold, df_agg, on=[MEMBER_ID_COL, 'year'], how='left')\n",
    "\n",
    "    # fill zeros for numeric-like columns\n",
    "    cols_to_fill = list(aggregation_rules.keys())\n",
    "    df_master[cols_to_fill] = df_master[cols_to_fill].fillna(0)\n",
    "\n",
    "    # Ensure boolean-like aggregated cols are numeric 0/1 (int)\n",
    "    bool_like_cols = ['count_inpatient', 'had_cardio', 'had_musculo', 'had_gastro', 'had_chemo']\n",
    "    for c in bool_like_cols:\n",
    "        if c in df_master.columns:\n",
    "            df_master[c] = df_master[c].replace({True: 1, False: 0}).fillna(0).astype(int)\n",
    "\n",
    "    # merge membership static fields\n",
    "    df_master = pd.merge(df_master, df_members, on=MEMBER_ID_COL, how='left')\n",
    "    df_master = df_master.dropna(subset=[MEMBER_DOB_COL, MEMBER_JOIN_DATE_COL])\n",
    "\n",
    "    print(\"Scaffold creation complete.\")\n",
    "    return df_master\n",
    "\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 4. FEATURE ENGINEERING (FIXED ROLLING + SAFE CASTS)\n",
    "# ==============================================================================\n",
    "def engineer_features(df_master):\n",
    "    print(\"Engineering features...\")\n",
    "    df_master = df_master.sort_values(by=[MEMBER_ID_COL, 'year']).reset_index(drop=True)\n",
    "\n",
    "    g = df_master.groupby(MEMBER_ID_COL)\n",
    "\n",
    "    def safe_rolling(series, window, func):\n",
    "        # Use groupby on member id, rolling, aggregate, shift, reset index to align\n",
    "        return (\n",
    "            series.groupby(df_master[MEMBER_ID_COL])\n",
    "            .rolling(window, min_periods=1)\n",
    "            .agg(func)\n",
    "            .shift(1)\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "    # helper\n",
    "    df_master['is_claim_free_year'] = (df_master['total_claim_count'] == 0).astype(int)\n",
    "\n",
    "    # demographics\n",
    "    df_master['age'] = df_master['year'] - pd.to_numeric(df_master[MEMBER_DOB_COL], errors='coerce')\n",
    "    df_master['tenure'] = df_master['year'] - df_master[MEMBER_JOIN_DATE_COL].dt.year\n",
    "    df_master['tenure'] = df_master['tenure'].clip(lower=0)\n",
    "\n",
    "    # Lag features (ensure numeric and fill NaNs)\n",
    "    df_master['cost_lag1'] = g['total_claim_amount'].shift(1).fillna(0).astype(float)\n",
    "    df_master['cost_lag2'] = g['total_claim_amount'].shift(2).fillna(0).astype(float)\n",
    "    df_master['claim_count_lag1'] = g['total_claim_count'].shift(1).fillna(0).astype(float)\n",
    "\n",
    "    # inpatient/count and condition lags: ensure they become numeric 0/1 or numeric\n",
    "    df_master['inpatient_count_lag1'] = g['count_inpatient'].shift(1).fillna(0).astype(int)\n",
    "\n",
    "    condition_lags = ['unique_conditions_count', 'had_cardio', 'had_musculo', 'had_gastro', 'had_chemo']\n",
    "    for col in condition_lags:\n",
    "        if col in df_master.columns:\n",
    "            if col == 'unique_conditions_count':\n",
    "                df_master[f'{col}_lag1'] = g[col].shift(1).fillna(0).astype(float)\n",
    "            else:\n",
    "                df_master[f'{col}_lag1'] = g[col].shift(1).fillna(0).astype(int)\n",
    "\n",
    "    # Rolling 3-year features (safe)\n",
    "    df_master['cost_avg_3yr'] = safe_rolling(df_master['total_claim_amount'], 3, 'mean').fillna(0).astype(float)\n",
    "    df_master['cost_max_3yr'] = safe_rolling(df_master['total_claim_amount'], 3, 'max').fillna(0).astype(float)\n",
    "    df_master['cost_std_3yr'] = safe_rolling(df_master['total_claim_amount'], 3, 'std').fillna(0).astype(float)\n",
    "    df_master['claim_free_years_3yr'] = safe_rolling(df_master['is_claim_free_year'], 3, 'sum').fillna(0).astype(int)\n",
    "\n",
    "    # Rolling 5-year features\n",
    "    df_master['cost_avg_5yr'] = safe_rolling(df_master['total_claim_amount'], 5, 'mean').fillna(0).astype(float)\n",
    "    df_master['cost_max_5yr'] = safe_rolling(df_master['total_claim_amount'], 5, 'max').fillna(0).astype(float)\n",
    "\n",
    "    # Target\n",
    "    df_master['target_cost_next_year'] = g['total_claim_amount'].shift(-1)\n",
    "\n",
    "    # Prepare model dataset\n",
    "    df_model_data = df_master.dropna(subset=['target_cost_next_year']).copy()\n",
    "\n",
    "    # Make sure required lag features exist and are numeric; drop rows where critical lags are missing\n",
    "    required_for_model = ['cost_lag1', 'cost_avg_3yr']\n",
    "    missing_req = [c for c in required_for_model if c not in df_model_data.columns]\n",
    "    if missing_req:\n",
    "        raise ValueError(f\"Missing required features after engineering: {missing_req}\")\n",
    "\n",
    "    df_model_data = df_model_data.dropna(subset=required_for_model)\n",
    "\n",
    "    # Final fill for any remaining numeric NaNs\n",
    "    numeric_cols = df_model_data.select_dtypes(include=['number']).columns.tolist()\n",
    "    df_model_data[numeric_cols] = df_model_data[numeric_cols].fillna(0)\n",
    "\n",
    "    # Ensure boolean-like columns are numeric\n",
    "    bool_like_lag_cols = ['inpatient_count_lag1', 'had_cardio_lag1', 'had_musculo_lag1', 'had_gastro_lag1', 'had_chemo_lag1']\n",
    "    for c in bool_like_lag_cols:\n",
    "        if c in df_model_data.columns:\n",
    "            df_model_data[c] = pd.to_numeric(df_model_data[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Drop helper column from final\n",
    "    df_model_data = df_model_data.drop(columns=['is_claim_free_year'], errors='ignore')\n",
    "    df_master = df_master.drop(columns=['is_claim_free_year'], errors='ignore')\n",
    "\n",
    "    print(f\"Feature engineering complete. Model-ready data has {len(df_model_data)} rows.\")\n",
    "    return df_model_data, df_master\n",
    "\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 5. TRAIN & VALIDATE MODEL\n",
    "# ==============================================================================\n",
    "def train_and_validate(df_model_data, validation_year):\n",
    "    print(f\"\\n--- Phase 1: Training & Validation on {validation_year} ---\")\n",
    "\n",
    "    target = 'target_cost_next_year'\n",
    "\n",
    "    static_features = [\n",
    "        MEMBER_GENDER_COL, MEMBER_POSTCODE_COL,\n",
    "        MEMBER_SCHEME_COL, MEMBER_STATUS_COL\n",
    "    ]\n",
    "\n",
    "    numeric_features = [\n",
    "        'age', 'tenure',\n",
    "        'cost_lag1', 'cost_lag2', 'claim_count_lag1', 'inpatient_count_lag1',\n",
    "        'cost_avg_3yr', 'cost_max_3yr', 'cost_std_3yr', 'claim_free_years_3yr',\n",
    "        'cost_avg_5yr', 'cost_max_5yr',\n",
    "        'unique_conditions_count_lag1', 'had_cardio_lag1', 'had_musculo_lag1',\n",
    "        'had_gastro_lag1', 'had_chemo_lag1'\n",
    "    ]\n",
    "\n",
    "    features = numeric_features + static_features\n",
    "    features = [f for f in features if f in df_model_data.columns]\n",
    "    static_features = [f for f in static_features if f in df_model_data.columns]\n",
    "\n",
    "    print(f\"\\nTraining with {len(features)} features: {features}\")\n",
    "\n",
    "    # Encode categorical static features (in-place)\n",
    "    encoders = {}\n",
    "    for col in static_features:\n",
    "        le = LabelEncoder()\n",
    "        df_model_data[col] = df_model_data[col].fillna('MISSING').astype(str)\n",
    "        df_model_data[col] = le.fit_transform(df_model_data[col])\n",
    "        encoders[col] = le\n",
    "\n",
    "    # Ensure all feature columns are numeric\n",
    "    for f in features:\n",
    "        if f in df_model_data.columns:\n",
    "            if df_model_data[f].dtype == 'object':\n",
    "                df_model_data[f] = pd.to_numeric(df_model_data[f], errors='coerce')\n",
    "    # final numeric fill\n",
    "    df_model_data[features] = df_model_data[features].fillna(0)\n",
    "\n",
    "    # Split: training uses years < validation_year-1, test uses year == validation_year-1\n",
    "    X_test_df = df_model_data[df_model_data['year'] == validation_year - 1].copy()\n",
    "    X_train_df = df_model_data[df_model_data['year'] < validation_year - 1].copy()\n",
    "\n",
    "    X_train = X_train_df[features]\n",
    "    y_train = X_train_df[target]\n",
    "    X_test = X_test_df[features]\n",
    "    y_test = X_test_df[target]\n",
    "\n",
    "    print(f\"Training on {len(X_train)} rows (Years {X_train_df['year'].min()}-{X_train_df['year'].max()})\")\n",
    "    print(f\"Validating on {len(X_test)} rows (Predicting year {validation_year})\")\n",
    "\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        objective='tweedie',\n",
    "        tweedie_variance_power=1.5,\n",
    "        metric='rmse',\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.01,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train with early stopping\n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=True)],\n",
    "        categorical_feature=static_features\n",
    "    )\n",
    "\n",
    "    y_pred_2025 = lgb_model.predict(X_test)\n",
    "    y_pred_2025[y_pred_2025 < 0] = 0\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred_2025)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_2025))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"--- VALIDATION RESULTS (PREDICTING {validation_year}) ---\")\n",
    "    print(f\"R-squared: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"Actual Avg Cost: {y_test.mean():.2f}\")\n",
    "    print(f\"Predicted Avg Cost: {y_pred_2025.mean():.2f}\")\n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': lgb_model.feature_name_,\n",
    "        'importance': lgb_model.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    print(\"\\n--- Top 20 Important Features ---\")\n",
    "    print(importance_df.head(20))\n",
    "\n",
    "    df_val_output = X_test_df.reset_index(drop=True)\n",
    "    df_val_output['actual_cost'] = y_test.reset_index(drop=True)\n",
    "    df_val_output['predicted_cost'] = y_pred_2025\n",
    "    df_val_output.to_csv('validation_predictions_2025.csv', index=False)\n",
    "    print(\"Saved validation predictions to: validation_predictions_2025.csv\")\n",
    "\n",
    "    return lgb_model, encoders, features, static_features\n",
    "\n",
    "\n",
    "# ============================================================================== \n",
    "# --- 6. MAIN EXECUTION\n",
    "# ==============================================================================\n",
    "def main_train():\n",
    "    print(\"--- Starting Model Training ---\")\n",
    "\n",
    "    df_claims, df_members = load_data(CLAIM_FILE_PATH, MEMBER_FILE_PATH)\n",
    "    if df_claims is None or df_members is None:\n",
    "        return\n",
    "\n",
    "    df_master = create_scaffold(df_claims, df_members, START_YEAR, END_YEAR)\n",
    "    df_model_data, _ = engineer_features(df_master.copy())\n",
    "    if df_model_data.empty:\n",
    "        print(\"Error: No model data created.\")\n",
    "        return\n",
    "\n",
    "    val_model, encoders, features, static_features = train_and_validate(df_model_data, VALIDATION_YEAR)\n",
    "\n",
    "    print(\"\\n--- Re-training final model on all data ---\")\n",
    "    target = 'target_cost_next_year'\n",
    "    X_full = df_model_data[features]\n",
    "    y_full = df_model_data[target]\n",
    "\n",
    "    final_model = lgb.LGBMRegressor(**val_model.get_params())\n",
    "    final_model.set_params(n_estimators=val_model.best_iteration_)\n",
    "    final_model.fit(X_full, y_full, categorical_feature=static_features)\n",
    "\n",
    "    joblib.dump(final_model, 'claim_model_method1.lgb')\n",
    "    joblib.dump(encoders, 'data_encoders.pkl')\n",
    "    joblib.dump(features, 'feature_list.pkl')\n",
    "\n",
    "    print(\"\\nArtifacts saved successfully.\")\n",
    "    print(\"--- Training Complete ---\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==============================================================================\n",
    "# --- CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "MODEL_PATH = \"trained_claim_model_ukpmi.lgb\"\n",
    "ENCODER_PATH = \"trained_encoders_ukpmi.pkl\"\n",
    "FEATURE_LIST_PATH = \"trained_features_ukpmi.pkl\"\n",
    "\n",
    "CLAIM_FILE_PATH = \"uk_pmi_claims_200k.csv\"\n",
    "MEMBER_FILE_PATH = \"uk_pmi_membership_120k.csv\"\n",
    "OUTPUT_FILE = \"predicted_claim_costs_2026.csv\"\n",
    "\n",
    "START_YEAR = 2019\n",
    "PREDICT_YEAR = 2026\n",
    "\n",
    "# ==============================================================================\n",
    "# --- FEATURE ENGINEERING (same as training)\n",
    "# ==============================================================================\n",
    "\n",
    "def preprocess_for_prediction(df_claims, df_members, start_year, end_year):\n",
    "    \"\"\"Builds lag/rolling features up to the given end_year.\"\"\"\n",
    "    print(f\"Building features up to {end_year}...\")\n",
    "\n",
    "    df_claims[\"Incurred Date\"] = pd.to_datetime(df_claims[\"Incurred Date\"], errors=\"coerce\")\n",
    "    df_claims[\"claim_year\"] = df_claims[\"Incurred Date\"].dt.year\n",
    "    df_claims[\"Claim Amount\"] = pd.to_numeric(df_claims[\"Claim Amount\"], errors=\"coerce\").fillna(0)\n",
    "    df_claims[\"Calculated Length of Service\"] = pd.to_numeric(df_claims[\"Calculated Length of Service\"], errors=\"coerce\").fillna(0)\n",
    "    df_claims = df_claims.dropna(subset=[\"Unique Member Reference\"])\n",
    "    df_claims = df_claims[df_claims[\"claim_year\"].between(start_year, end_year)]\n",
    "\n",
    "    # --- Aggregate claim features ---\n",
    "    def had_condition(series, keyword):\n",
    "        return (series.str.contains(keyword, case=False, na=False)).any()\n",
    "\n",
    "    agg = df_claims.groupby([\"Unique Member Reference\", \"claim_year\"]).agg(\n",
    "        total_claim_amount=(\"Claim Amount\", \"sum\"),\n",
    "        total_claim_count=(\"Claim Amount\", \"count\"),\n",
    "        total_los=(\"Calculated Length of Service\", \"sum\"),\n",
    "        count_inpatient=(\"Claim Type\", lambda x: (x == \"Inpatient\").sum()),\n",
    "        unique_conditions_count=(\"Condition Category\", \"nunique\"),\n",
    "        had_cardio=(\"Condition Category\", lambda s: had_condition(s, \"Cardio\")),\n",
    "        had_musculo=(\"Condition Category\", lambda s: had_condition(s, \"Musculo\")),\n",
    "        had_gastro=(\"Condition Category\", lambda s: had_condition(s, \"Gastro\")),\n",
    "        had_chemo=(\"Condition Category\", lambda s: had_condition(s, \"Chemo\")),\n",
    "    ).reset_index()\n",
    "\n",
    "    agg = agg.rename(columns={\"claim_year\": \"year\"})\n",
    "    all_members = df_members[\"Unique Member Reference\"].unique()\n",
    "    all_years = list(range(start_year, end_year + 1))\n",
    "    scaffold = pd.MultiIndex.from_product([all_members, all_years], names=[\"Unique Member Reference\", \"year\"])\n",
    "    df_scaffold = pd.DataFrame(index=scaffold).reset_index()\n",
    "\n",
    "    df_master = pd.merge(df_scaffold, agg, on=[\"Unique Member Reference\", \"year\"], how=\"left\").fillna(0)\n",
    "\n",
    "    # --- Merge membership info ---\n",
    "    df_master = df_master.merge(df_members, on=\"Unique Member Reference\", how=\"left\")\n",
    "\n",
    "    # --- Derived features ---\n",
    "    df_master[\"age\"] = df_master[\"year\"] - pd.to_numeric(df_master[\"Year of Birth\"], errors=\"coerce\")\n",
    "    df_master[\"Original Date of Joining\"] = pd.to_datetime(df_master[\"Original Date of Joining\"], errors=\"coerce\")\n",
    "    df_master[\"tenure\"] = df_master[\"year\"] - df_master[\"Original Date of Joining\"].dt.year\n",
    "    df_master[\"tenure\"] = df_master[\"tenure\"].clip(lower=0)\n",
    "\n",
    "    df_master = df_master.sort_values([\"Unique Member Reference\", \"year\"]).reset_index(drop=True)\n",
    "    g = df_master.groupby(\"Unique Member Reference\")\n",
    "\n",
    "    # --- Lag features ---\n",
    "    df_master[\"cost_lag1\"] = g[\"total_claim_amount\"].shift(1)\n",
    "    df_master[\"cost_lag2\"] = g[\"total_claim_amount\"].shift(2)\n",
    "    df_master[\"claim_count_lag1\"] = g[\"total_claim_count\"].shift(1)\n",
    "    df_master[\"inpatient_count_lag1\"] = g[\"count_inpatient\"].shift(1)\n",
    "    for c in [\"unique_conditions_count\", \"had_cardio\", \"had_musculo\", \"had_gastro\", \"had_chemo\"]:\n",
    "        df_master[f\"{c}_lag1\"] = g[c].shift(1)\n",
    "\n",
    "    # --- Rolling stats ---\n",
    "    rolling = lambda x, w, f: x.groupby(df_master[\"Unique Member Reference\"]).rolling(w, min_periods=1).agg(f).shift(1).reset_index(level=0, drop=True)\n",
    "    df_master[\"cost_avg_3yr\"] = rolling(df_master[\"total_claim_amount\"], 3, \"mean\")\n",
    "    df_master[\"cost_max_3yr\"] = rolling(df_master[\"total_claim_amount\"], 3, \"max\")\n",
    "    df_master[\"cost_std_3yr\"] = rolling(df_master[\"total_claim_amount\"], 3, \"std\")\n",
    "    df_master[\"claim_free_years_3yr\"] = rolling((df_master[\"total_claim_count\"] == 0).astype(int), 3, \"sum\")\n",
    "    df_master[\"cost_avg_5yr\"] = rolling(df_master[\"total_claim_amount\"], 5, \"mean\")\n",
    "    df_master[\"cost_max_5yr\"] = rolling(df_master[\"total_claim_amount\"], 5, \"max\")\n",
    "\n",
    "    df_master = df_master.fillna(0)\n",
    "    return df_master\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- INFERENCE FUNCTION\n",
    "# ==============================================================================\n",
    "\n",
    "def predict_claims_2026():\n",
    "    print(\"\\n--- Predicting Claim Costs for 2026 ---\")\n",
    "\n",
    "    # Load trained model and preprocessing objects\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    encoders = joblib.load(ENCODER_PATH)\n",
    "    features = joblib.load(FEATURE_LIST_PATH)\n",
    "\n",
    "    # Load raw data\n",
    "    df_claims = pd.read_csv(CLAIM_FILE_PATH)\n",
    "    df_members = pd.read_csv(MEMBER_FILE_PATH)\n",
    "\n",
    "    # Build all features up to 2025\n",
    "    df_master = preprocess_for_prediction(df_claims, df_members, START_YEAR, 2025)\n",
    "    df_latest = df_master[df_master[\"year\"] == 2025].copy()\n",
    "\n",
    "    # Encode categoricals\n",
    "    for col, le in encoders.items():\n",
    "        if col in df_latest.columns:\n",
    "            df_latest[col] = df_latest[col].astype(str)\n",
    "            unseen = ~df_latest[col].isin(le.classes_)\n",
    "            if unseen.any():\n",
    "                df_latest.loc[unseen, col] = \"MISSING\"\n",
    "                le.classes_ = np.append(le.classes_, \"MISSING\")\n",
    "            df_latest[col] = le.transform(df_latest[col])\n",
    "\n",
    "    # Align features\n",
    "    for f in features:\n",
    "        if f not in df_latest.columns:\n",
    "            df_latest[f] = 0\n",
    "    df_latest = df_latest[features].fillna(0)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(df_latest)\n",
    "    preds = np.maximum(preds, 0)\n",
    "\n",
    "    df_output = pd.DataFrame({\n",
    "        \"Unique Member Reference\": df_master[df_master[\"year\"] == 2025][\"Unique Member Reference\"],\n",
    "        \"predicted_claim_cost_2026\": preds\n",
    "    })\n",
    "\n",
    "    df_output.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"âœ… Predictions for 2026 saved to {OUTPUT_FILE}\")\n",
    "    print(df_output.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_claims_2026()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
